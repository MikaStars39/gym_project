# SPDX-FileCopyrightText: Copyright (c) 2021 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: BSD-3-Clause

import os
import numpy as np
import torch
import matplotlib.pyplot as plt
from datetime import datetime
import json

from legged_gym.envs import *
from legged_gym.utils import get_args, task_registry
import isaacgym


def headless_record_policy(args):
    """
    åœ¨æ— GUIç¯å¢ƒä¸‹è®°å½•ç­–ç•¥è¡¨ç°å’Œç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
    ä¸ä¾èµ–å®æ—¶æ¸²æŸ“ï¼Œé€šè¿‡æ•°æ®åˆ†æç”Ÿæˆå¯è§†åŒ–å†…å®¹
    """
    
    print("ğŸ¬ æ— GUIç¯å¢ƒç­–ç•¥å½•åˆ¶å¼€å§‹...")
    
    # Load environment configuration
    env_cfg, train_cfg = task_registry.get_cfgs(name=args.task)
    
    # ä¼˜åŒ–é…ç½®ç”¨äºæ•°æ®æ”¶é›†
    env_cfg.env.num_envs = 16  # å°æ‰¹é‡ç”¨äºè¯¦ç»†åˆ†æ
    env_cfg.terrain.num_rows = 5
    env_cfg.terrain.num_cols = 5
    env_cfg.terrain.curriculum = False
    env_cfg.noise.add_noise = False
    env_cfg.domain_rand.randomize_friction = False
    env_cfg.domain_rand.push_robots = False
    
    # Create environment (headless)
    env, _ = task_registry.make_env(name=args.task, args=args, env_cfg=env_cfg)
    
    # Load policy if available
    policy = None
    if args.run_name:
        try:
            train_cfg.runner.resume = True
            ppo_runner, _ = task_registry.make_alg_runner(env=env, name=args.task, args=args, train_cfg=train_cfg)
            policy = ppo_runner.get_inference_policy(device=env.device)
            print(f"âœ… æˆåŠŸåŠ è½½ç­–ç•¥: {args.run_name}")
        except Exception as e:
            print(f"âš ï¸  ç­–ç•¥åŠ è½½å¤±è´¥: {e}")
            print("ğŸ² å°†ä½¿ç”¨éšæœºåŠ¨ä½œè¿›è¡Œæ¼”ç¤º")
    
    # Setup recording
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_dir = f"recordings/{args.task}_{timestamp}"
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    # Data collection
    episode_data = []
    step_data = []
    terrain_performance = {}
    
    total_steps = 2000
    print(f"ğŸ“Š å¼€å§‹æ”¶é›† {total_steps} æ­¥æ•°æ®...")
    
    obs = env.get_observations()
    
    for step in range(total_steps):
        # Get actions
        if policy is not None:
            with torch.no_grad():
                actions = policy(obs.detach())
        else:
            # Random actions for demonstration
            actions = torch.randn(env.num_envs, env.num_actions, device=env.device) * 0.5
        
        # Step environment
        obs, rewards, dones, infos = env.step(actions.detach())
        
        # Collect step data
        step_info = {
            'step': step,
            'mean_reward': torch.mean(rewards).item(),
            'base_height': torch.mean(env.root_states[:, 2]).item() if hasattr(env, 'root_states') else 0,
            'linear_velocity': torch.mean(torch.norm(env.base_lin_vel[:, :2], dim=1)).item() if hasattr(env, 'base_lin_vel') else 0,
            'angular_velocity': torch.mean(torch.abs(env.base_ang_vel[:, 2])).item() if hasattr(env, 'base_ang_vel') else 0,
        }
        step_data.append(step_info)
        
        # Track episode completions
        if torch.any(dones):
            done_envs = torch.where(dones)[0]
            for env_idx in done_envs:
                episode_length = env.episode_length_buf[env_idx].item() if hasattr(env, 'episode_length_buf') else step
                survival_time = episode_length * env.dt if hasattr(env, 'dt') else episode_length * 0.02
                
                episode_info = {
                    'episode_length': episode_length,
                    'survival_time': survival_time,
                    'final_reward': rewards[env_idx].item(),
                    'terrain_level': getattr(env, 'terrain_levels', torch.zeros(env.num_envs))[env_idx].item(),
                    'terrain_type': getattr(env, 'terrain_types', torch.zeros(env.num_envs))[env_idx].item(),
                }
                episode_data.append(episode_info)
        
        # Progress update
        if step % 200 == 0:
            progress = (step / total_steps) * 100
            print(f"ğŸ“ˆ è¿›åº¦: {progress:.1f}% - å¹³å‡å¥–åŠ±: {step_info['mean_reward']:.3f}")
    
    print("âœ… æ•°æ®æ”¶é›†å®Œæˆï¼Œç”Ÿæˆå¯è§†åŒ–...")
    
    # Generate visualizations
    create_performance_plots(output_dir, step_data, episode_data, args.task)
    
    # Save raw data
    save_data(output_dir, step_data, episode_data, args)
    
    # Generate summary report
    generate_summary_report(output_dir, step_data, episode_data, args.task)
    
    print(f"ğŸ‰ å½•åˆ¶å®Œæˆï¼æ–‡ä»¶ä¿å­˜è‡³: {output_dir}")
    print("ğŸ“‹ ç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  ğŸ“Š performance_analysis.png - æ€§èƒ½åˆ†æå›¾")
    print(f"  ğŸ“ˆ training_curves.png - è®­ç»ƒæ›²çº¿")
    print(f"  ğŸ—ƒï¸  raw_data.json - åŸå§‹æ•°æ®")
    print(f"  ğŸ“„ summary_report.txt - æ€»ç»“æŠ¥å‘Š")


def create_performance_plots(output_dir, step_data, episode_data, task_name):
    """ç”Ÿæˆæ€§èƒ½åˆ†æå›¾è¡¨"""
    
    # Create comprehensive performance visualization
    fig = plt.figure(figsize=(16, 12))
    
    # 1. Reward over time
    ax1 = plt.subplot(3, 3, 1)
    steps = [d['step'] for d in step_data]
    rewards = [d['mean_reward'] for d in step_data]
    plt.plot(steps, rewards, 'b-', alpha=0.7)
    plt.title('å¹³å‡å¥–åŠ±éšæ—¶é—´å˜åŒ–')
    plt.xlabel('æ­¥æ•°')
    plt.ylabel('å¥–åŠ±')
    plt.grid(True, alpha=0.3)
    
    # 2. Velocity tracking
    ax2 = plt.subplot(3, 3, 2)
    velocities = [d['linear_velocity'] for d in step_data]
    plt.plot(steps, velocities, 'g-', alpha=0.7)
    plt.title('çº¿é€Ÿåº¦')
    plt.xlabel('æ­¥æ•°')
    plt.ylabel('é€Ÿåº¦ (m/s)')
    plt.grid(True, alpha=0.3)
    
    # 3. Base height stability
    ax3 = plt.subplot(3, 3, 3)
    heights = [d['base_height'] for d in step_data]
    plt.plot(steps, heights, 'r-', alpha=0.7)
    plt.title('æœºå™¨äººé«˜åº¦')
    plt.xlabel('æ­¥æ•°')
    plt.ylabel('é«˜åº¦ (m)')
    plt.grid(True, alpha=0.3)
    
    # 4. Episode survival times
    if episode_data:
        ax4 = plt.subplot(3, 3, 4)
        survival_times = [d['survival_time'] for d in episode_data]
        plt.hist(survival_times, bins=20, alpha=0.7, color='orange')
        plt.title('ç”Ÿå­˜æ—¶é—´åˆ†å¸ƒ')
        plt.xlabel('ç”Ÿå­˜æ—¶é—´ (ç§’)')
        plt.ylabel('é¢‘æ¬¡')
        plt.axvline(x=10, color='red', linestyle='--', label='ç›®æ ‡: 10ç§’')
        plt.legend()
    
    # 5. Terrain performance
    if episode_data:
        ax5 = plt.subplot(3, 3, 5)
        terrain_levels = [d['terrain_level'] for d in episode_data]
        if terrain_levels:
            plt.hist(terrain_levels, bins=10, alpha=0.7, color='purple')
            plt.title('åœ°å½¢éš¾åº¦åˆ†å¸ƒ')
            plt.xlabel('åœ°å½¢ç­‰çº§')
            plt.ylabel('å®Œæˆæ¬¡æ•°')
    
    # 6. Angular velocity
    ax6 = plt.subplot(3, 3, 6)
    ang_velocities = [d['angular_velocity'] for d in step_data]
    plt.plot(steps, ang_velocities, 'purple', alpha=0.7)
    plt.title('è§’é€Ÿåº¦')
    plt.xlabel('æ­¥æ•°')
    plt.ylabel('è§’é€Ÿåº¦ (rad/s)')
    plt.grid(True, alpha=0.3)
    
    # 7. Performance metrics summary
    ax7 = plt.subplot(3, 3, 7)
    if episode_data:
        avg_survival = np.mean([d['survival_time'] for d in episode_data])
        survival_success = np.mean([1 if d['survival_time'] > 10 else 0 for d in episode_data])
        avg_reward = np.mean([d['final_reward'] for d in episode_data])
        
        metrics = ['å¹³å‡ç”Ÿå­˜æ—¶é—´', 'ç”Ÿå­˜æˆåŠŸç‡', 'å¹³å‡å¥–åŠ±']
        values = [avg_survival, survival_success * 100, avg_reward * 10]  # Scale for visibility
        colors = ['green', 'blue', 'orange']
        
        bars = plt.bar(metrics, values, color=colors, alpha=0.7)
        plt.title('å…³é”®æŒ‡æ ‡')
        plt.xticks(rotation=45)
        
        # Add value labels
        for bar, value in zip(bars, [avg_survival, survival_success, avg_reward]):
            height = bar.get_height()
            if bar == bars[0]:  # Survival time
                plt.text(bar.get_x() + bar.get_width()/2., height,
                        f'{value:.1f}s', ha='center', va='bottom')
            elif bar == bars[1]:  # Success rate
                plt.text(bar.get_x() + bar.get_width()/2., height,
                        f'{value:.1%}', ha='center', va='bottom')
            else:  # Reward
                plt.text(bar.get_x() + bar.get_width()/2., height,
                        f'{value:.2f}', ha='center', va='bottom')
    
    # 8. Robot info
    ax8 = plt.subplot(3, 3, 8)
    ax8.text(0.1, 0.8, f'æœºå™¨äºº: {task_name.upper()}', fontsize=14, weight='bold')
    if task_name == 'g1':
        ax8.text(0.1, 0.6, 'â€¢ 23è‡ªç”±åº¦ç´§å‡‘å‹', fontsize=10)
        ax8.text(0.1, 0.5, 'â€¢ å…¨èº«è¿åŠ¨æ§åˆ¶', fontsize=10)
    elif task_name == 'h1':
        ax8.text(0.1, 0.6, 'â€¢ å…¨å°ºå¯¸äººå½¢æœºå™¨äºº', fontsize=10)
        ax8.text(0.1, 0.5, 'â€¢ å¢å¼ºç¨³å®šæ€§', fontsize=10)
    
    ax8.text(0.1, 0.3, 'â€¢ å¤æ‚åœ°å½¢å¯¼èˆª', fontsize=10)
    ax8.text(0.1, 0.2, 'â€¢ å¯¹ç§°è¿åŠ¨çº¦æŸ', fontsize=10)
    ax8.set_xlim(0, 1)
    ax8.set_ylim(0, 1)
    ax8.axis('off')
    
    # 9. Terrain distribution
    ax9 = plt.subplot(3, 3, 9)
    terrain_names = ['å¹³ç¼“æ–œå¡', 'ç²—ç³™æ–œå¡', 'ä¸Šæ¥¼æ¢¯', 'ä¸‹æ¥¼æ¢¯', 'ç¦»æ•£', 'è¸è„šçŸ³', 'é—´éš™']
    terrain_props = [0.25, 0.25, 0.1, 0.1, 0.1, 0.1, 0.1]
    plt.pie(terrain_props, labels=terrain_names, autopct='%1.1f%%', startangle=90)
    plt.title('åœ°å½¢åˆ†å¸ƒ')
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'performance_analysis.png'), dpi=300, bbox_inches='tight')
    plt.close()


def save_data(output_dir, step_data, episode_data, args):
    """ä¿å­˜åŸå§‹æ•°æ®"""
    data = {
        'task': args.task,
        'run_name': args.run_name,
        'timestamp': datetime.now().isoformat(),
        'step_data': step_data,
        'episode_data': episode_data
    }
    
    with open(os.path.join(output_dir, 'raw_data.json'), 'w') as f:
        json.dump(data, f, indent=2)


def generate_summary_report(output_dir, step_data, episode_data, task_name):
    """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
    
    report = []
    report.append("="*60)
    report.append(f"Isaac Gym {task_name.upper()} ç­–ç•¥æ€§èƒ½æŠ¥å‘Š")
    report.append("="*60)
    report.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append("")
    
    if step_data:
        avg_reward = np.mean([d['mean_reward'] for d in step_data])
        avg_velocity = np.mean([d['linear_velocity'] for d in step_data])
        avg_height = np.mean([d['base_height'] for d in step_data])
        
        report.append("ğŸ“Š æ•´ä½“æ€§èƒ½æŒ‡æ ‡:")
        report.append(f"  â€¢ å¹³å‡å¥–åŠ±: {avg_reward:.3f}")
        report.append(f"  â€¢ å¹³å‡çº¿é€Ÿåº¦: {avg_velocity:.3f} m/s")
        report.append(f"  â€¢ å¹³å‡æœºå™¨äººé«˜åº¦: {avg_height:.3f} m")
        report.append("")
    
    if episode_data:
        survival_times = [d['survival_time'] for d in episode_data]
        avg_survival = np.mean(survival_times)
        max_survival = np.max(survival_times)
        survival_success = np.mean([1 if t > 10 else 0 for t in survival_times])
        
        report.append("ğŸ• ç”Ÿå­˜æ—¶é—´åˆ†æ:")
        report.append(f"  â€¢ å¹³å‡ç”Ÿå­˜æ—¶é—´: {avg_survival:.2f} ç§’")
        report.append(f"  â€¢ æœ€å¤§ç”Ÿå­˜æ—¶é—´: {max_survival:.2f} ç§’")
        report.append(f"  â€¢ ç”Ÿå­˜æˆåŠŸç‡ (>10s): {survival_success:.1%}")
        
        # Check success criteria
        if avg_survival > 10:
            report.append("  âœ… æ»¡è¶³ç”Ÿå­˜æ—¶é—´è¦æ±‚")
        else:
            report.append("  âŒ æœªæ»¡è¶³ç”Ÿå­˜æ—¶é—´è¦æ±‚")
        report.append("")
        
        terrain_levels = [d['terrain_level'] for d in episode_data]
        if terrain_levels:
            avg_terrain_level = np.mean(terrain_levels)
            max_terrain_level = np.max(terrain_levels)
            
            report.append("ğŸ”ï¸  åœ°å½¢é€‚åº”æ€§:")
            report.append(f"  â€¢ å¹³å‡åœ°å½¢ç­‰çº§: {avg_terrain_level:.1f}")
            report.append(f"  â€¢ æœ€å¤§åœ°å½¢ç­‰çº§: {max_terrain_level}")
            report.append("")
    
    # Performance evaluation based on task requirements
    report.append("ğŸ¯ ä»»åŠ¡è¦æ±‚è¯„ä¼°:")
    if task_name == 'g1':
        report.append("  G1 ä½é€Ÿè¡Œèµ°è¦æ±‚:")
        report.append("  â€¢ xyé€Ÿåº¦: [0.0, 1.0] m/s")
        report.append("  â€¢ é€Ÿåº¦è·Ÿè¸ªè¯¯å·® < 0.25 m/s")
        report.append("  â€¢ ç”Ÿå­˜æ—¶é—´ > 10s")
    elif task_name == 'h1':
        report.append("  H1 è¡Œèµ°è¦æ±‚:")
        report.append("  â€¢ xyé€Ÿåº¦: [0.0, 1.0] m/s") 
        report.append("  â€¢ é€Ÿåº¦è·Ÿè¸ªè¯¯å·® < 0.25 m/s")
        report.append("  â€¢ ç”Ÿå­˜æ—¶é—´ > 10s")
    
    report.append("")
    report.append("ğŸ“ ç”Ÿæˆæ–‡ä»¶:")
    report.append("  â€¢ performance_analysis.png - æ€§èƒ½åˆ†æå›¾è¡¨")
    report.append("  â€¢ raw_data.json - åŸå§‹æ•°æ®")
    report.append("  â€¢ summary_report.txt - æœ¬æŠ¥å‘Š")
    
    # Write report
    with open(os.path.join(output_dir, 'summary_report.txt'), 'w', encoding='utf-8') as f:
        f.write('\n'.join(report))


if __name__ == '__main__':
    args = get_args()
    headless_record_policy(args) 